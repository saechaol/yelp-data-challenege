{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC 180 Assignment 1\n",
    "## Lucas Saechao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import sklearn.feature_extraction.text as sk_extract_feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from collections.abc import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "if os.name == 'nt':\n",
    "    import winsound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions:\n",
    "## encode_text_index\n",
    "Encodes textual values to indices format.\n",
    "\n",
    "## ecnode_numeric_zscore\n",
    "Computes and encodes a given column as its z-score.\n",
    "\n",
    "## chart_regression\n",
    "Prints a chart representing the model's regression.\n",
    "\n",
    "## to_xy\n",
    "Converts a pandas DataFrame into <x, y> inputs as required for TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode textual values into indices\n",
    "def encode_text_index(df, name):\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    df[name] = label_encoder.fit_transform(df[name])\n",
    "    return label_encoder.classes_\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "    \n",
    "# Regression chart\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten() })\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(), label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Convert a Pandas DataFrame to the x, y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    \n",
    "    # Find out the type of the target column\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    \n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bit values\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Helper function prints a progress bar to the screen for long scripts, i.e. reading large datasets.\n",
    "def progress_bar(curr_progress):\n",
    "    l = 20\n",
    "    if isinstance (curr_progress, int):\n",
    "        curr_progress = float(curr_progress)\n",
    "    if not isinstance(curr_progress, float):\n",
    "        curr_progress = 0\n",
    "        print(\"error: progress var must be float\\r\\n\")\n",
    "    if curr_progress < 0:\n",
    "        curr_progress = 0\n",
    "        print(\"Halt...\\r\\n\")\n",
    "    if curr_progress >= 1:\n",
    "        curr_progress = 1\n",
    "        print(\"Done...\\r\\n\")\n",
    "    block = int(round(l * curr_progress))\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    prog = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (l - block), curr_progress * 100)\n",
    "    print(prog)\n",
    "\n",
    "# Play a noise following the end of a script\n",
    "def ping(say=\"I'm done\"):\n",
    "    if os.name == 'nt': # If this is a windows machine\n",
    "        winsound.Beep(2000, 150)\n",
    "        winsound.Beep(2000, 150)\n",
    "        winsound.Beep(2000, 150)\n",
    "    else: # If this is anything else but a windows machine\n",
    "        os.system('say \"{}\"'.format(say))\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out business with less than 20 reviews\n",
    "For each business in which its 'review_count' value is greater than 20, write to a tab separated values (tsv) file its ID, star rating, and review count. The resulting file is then read into a pandas DataFrame and printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####----------------] 18.7%\n"
     ]
    }
   ],
   "source": [
    "outfile = open(\"business.tsv\", 'w')\n",
    "data_file = csv.writer(outfile, delimiter=\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "data_file.writerow(['business_id', 'name', 'stars', 'review_count'])\n",
    "\n",
    "# Open data from file path\n",
    "with open('data/yelp_academic_dataset_business.json', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        if (row['review_count'] >= 20):\n",
    "            data_file.writerow([row['business_id'], row['name'], row['stars'], (row['review_count'])])\n",
    "        i = i + 1\n",
    "        progress_bar(i / 160000)\n",
    "progress_bar(1);\n",
    "outfile.close()\n",
    "ping(\"File has been read from yelp academic dataset business.json\")\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe output file\n",
    "df_business = pd.read_csv('business.tsv', delimiter=\"\\t\", encoding=\"utf-8\")\n",
    "df_all = df_business[['business_id', 'name', 'stars', 'review_count']]\n",
    "df_stars = df_business[['business_id', 'name', 'stars']]\n",
    "df_reviews = df_business[['business_id', 'name','review_count']]\n",
    "print (df_business)\n",
    "print (df_stars)\n",
    "print (df_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out review text by business and star rating\n",
    "Choose a few arbitrary businesses to fetch reviews for, and map them into a dictionary. For each business in ```yelp_academic_dataset_review.json```, if its ID exists in ```business_map```, write its ID, star rating, and review text to ```reviews_by_stars.tsv```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbitrarily choose businesses to search reviews for\n",
    "#business_map = {'SYa2j1boLF8DcGVOYfHPcA':'Five Guys', 'JjcJVqhZXhP4tvOhg3fnag':'Water Heater Pros', 'fNil19SUfPAPnLQrYnFrGQ':'Cheyenne West Animal Hospital', 'xVpE01l6ZXdEtVf5PkRpDg':'Julep', 'YZeUH6zYS0dq5QHLYZhUnQ':'Hooters'}\n",
    "\n",
    "# write a tsv file with review text\n",
    "outfile = open('reviews_by_stars.tsv', 'w')\n",
    "file_writer = csv.writer(outfile, delimiter = \"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "file_writer.writerow(['business_id', 'stars', 'text'])\n",
    "\n",
    "# Open data from path\n",
    "with open('data/yelp_academic_dataset_review.json', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # pull mapped business from json\n",
    "        if (row['business_id'] in df_business['business_id'].tolist()):\n",
    "            file_writer.writerow( [row['business_id'], row['stars'], (row['text']).encode('utf-8')])\n",
    "        progress_bar(i / 2000000)\n",
    "        i = i + 1\n",
    "progress_bar(1)\n",
    "outfile.close()\n",
    "ping(\"File has been read from yelp academic dataset review.json\")\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe output file\n",
    "df = pd.read_csv('reviews_by_stars.tsv', delimiter = \"\\t\", encoding = \"utf-8\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for language processing\n",
    "For each business, aggregate its review data into a single column, and merge the resulting DataFrame with its corresponding star rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate_reviews = df.groupby('business_id')['text'].sum()\n",
    "df_reviews_by_stars = pd.merge(df_aggregate_reviews, df_stars, on = 'business_id')\n",
    "print(df_reviews_by_stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TF-IDF Vectorizer\n",
    "Prepare the vectorizer and fit it to the merged ```df_reviews_by_stars``` DataFrame, and apply it to the review column. After the TF-IDF vectorizer is run, merge it with the original data frame by its review text, and drop any unnecessary columns to prepare a DataFrame for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = sk_extract_feature.TfidfVectorizer(stop_words='english', max_features = 1000, min_df=1)\n",
    "review_vector = tfidf_vectorizer.fit_transform(df_reviews_by_stars['text'])\n",
    "\n",
    "df_vectorized_reviews = pd.DataFrame(review_vector.toarray())\n",
    "df_concat_reviews = pd.concat([df_reviews_by_stars, df_vectorized_reviews], axis=1)\n",
    "businesses = df_concat_reviews['name']\n",
    "\n",
    "df_neural_network = df_concat_reviews.drop(['business_id', 'text', 'name'], axis=1)\n",
    "print(df_neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare text dummy\n",
    "x, y = to_xy(df_neural_network, \"stars\")\n",
    "\n",
    "# Split training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state = 40)\n",
    "\n",
    "# Print data shape\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, input_dim=x.shape[1], activation='tanh'))\n",
    "model.add(Dense(250, activation='sigmoid'))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=2, mode='auto')\n",
    "checkpoint = ModelCheckpoint(filepath=\"weight/best_weights.hdf5\")\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor, checkpoint], verbose=2, epochs=1000)\n",
    "\n",
    "model.load_weights(\"weight/best_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(x_test)\n",
    "print(\"Shape: {}\".format(pred_test.shape))\n",
    "print(pred_test)\n",
    "\n",
    "pred_train = model.predict(x_train)\n",
    "print(pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure RMSE error\n",
    "Root Means Squared Error is commonly used to analyze results of regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(metrics.mean_squared_error(pred_test, y_test))\n",
    "print(\"Root Means Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pred_test.shape[0]):\n",
    "    print(\"{}. Business: {}, Rating: {}, Predicted Rating: {}\".format(i + 1, businesses[i], y[i], pred_test[i]))\n",
    "\n",
    "for i in range(pred_train.shape[0]):\n",
    "    print(\"{}. Business: {}, Rating: {}, Predicted Rating: {}\".format(i + 4, businesses[i + 3], y[i + 3], pred_test[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print prediction\n",
    "Merge the prediction and test columns together and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_test = pd.DataFrame(y_test, columns=['ground_truth'])\n",
    "df_predicted = pd.DataFrame(pred_test, columns=['predicted'])\n",
    "prediction_result = pd.concat([df_y_test, df_predicted], axis=1)\n",
    "prediction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_regression(pred_test.flatten(), y_test, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
